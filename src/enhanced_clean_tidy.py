"""
Enhanced Bookmark Processing System - å¢å¼ºç‰ˆä¹¦ç­¾å¤„ç†ç³»ç»Ÿ

ä¸»è¦æ”¹è¿›ï¼š
1. å¹¶è¡Œå¤„ç†èƒ½åŠ›
2. å®æ—¶è¿›åº¦æ˜¾ç¤º
3. å¢é‡å¤„ç†æ”¯æŒ
4. æ™ºèƒ½å»é‡ç³»ç»Ÿ
5. å¤šæ ¼å¼è¾“å‡º
6. è¯¦ç»†ç»Ÿè®¡åˆ†æ
"""

import os
import sys
import argparse
import json
import glob
import time
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import logging
from dataclasses import dataclass
from datetime import datetime
import hashlib
from bs4 import BeautifulSoup
import html

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from enhanced_classifier import EnhancedClassifier, ClassificationResult

@dataclass
class ProcessingStats:
    """å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    total_bookmarks: int = 0
    processed_bookmarks: int = 0
    duplicates_removed: int = 0
    errors_count: int = 0
    start_time: datetime = None
    end_time: datetime = None
    categories_found: Dict[str, int] = None
    avg_confidence: float = 0.0
    processing_speed: float = 0.0  # ä¹¦ç­¾/ç§’
    
    def __post_init__(self):
        if self.categories_found is None:
            self.categories_found = {}

class EnhancedBookmarkProcessor:
    """å¢å¼ºç‰ˆä¹¦ç­¾å¤„ç†å™¨"""
    
    def __init__(self, config_file: str = "config.json", max_workers: int = 4):
        self.config_file = config_file
        self.max_workers = max_workers
        self.classifier = EnhancedClassifier(config_file)
        
        # å¤„ç†çŠ¶æ€
        self.processed_bookmarks = []
        self.stats = ProcessingStats()
        self.seen_urls = set()
        self.duplicate_hashes = set()
        
        # çº¿ç¨‹å®‰å…¨é”
        self.stats_lock = Lock()
        self.seen_urls_lock = Lock()
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
        
        # åŠ è½½å­¦ä¹ æ•°æ®
        self.classifier.load_learning_data()
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # æ§åˆ¶å°è¾“å‡º
            console_handler = logging.StreamHandler()
            console_formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)
            
            # æ–‡ä»¶è¾“å‡º
            os.makedirs('logs', exist_ok=True)
            file_handler = logging.FileHandler(
                f'logs/processing_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
                encoding='utf-8'
            )
            file_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)
        
        return logger
    
    def load_bookmarks_from_files(self, input_files: List[str]) -> List[Dict]:
        """ä»å¤šä¸ªHTMLæ–‡ä»¶åŠ è½½ä¹¦ç­¾"""
        all_bookmarks = []
        
        self.logger.info(f"å¼€å§‹åŠ è½½ {len(input_files)} ä¸ªä¹¦ç­¾æ–‡ä»¶...")
        
        for file_path in input_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                soup = BeautifulSoup(content, 'lxml')
                links = soup.find_all('a')
                
                file_bookmarks = []
                for link in links:
                    url = link.get('href', '').strip()
                    title = (link.string or link.get_text() or url).strip()
                    
                    if url and title and self._is_valid_url(url):
                        file_bookmarks.append({
                            'url': url,
                            'title': title,
                            'source_file': file_path,
                            'add_date': link.get('add_date', ''),
                            'last_modified': link.get('last_modified', '')
                        })
                
                all_bookmarks.extend(file_bookmarks)
                self.logger.info(f"ä» {file_path} åŠ è½½äº† {len(file_bookmarks)} ä¸ªä¹¦ç­¾")
                
            except Exception as e:
                self.logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        
        self.logger.info(f"æ€»å…±åŠ è½½äº† {len(all_bookmarks)} ä¸ªä¹¦ç­¾")
        return all_bookmarks
    
    def _is_valid_url(self, url: str) -> bool:
        """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
        if not url:
            return False
        
        # è¿‡æ»¤æ‰æ— æ•ˆçš„URL
        invalid_prefixes = ['javascript:', 'data:', 'chrome:', 'about:', 'file:', 'mailto:']
        for prefix in invalid_prefixes:
            if url.lower().startswith(prefix):
                return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„HTTP/HTTPS URL
        return url.startswith(('http://', 'https://'))
    
    def _generate_content_hash(self, url: str, title: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œç”¨äºå»é‡"""
        # æ ‡å‡†åŒ–URL
        normalized_url = self._normalize_url(url)
        
        # æ ‡å‡†åŒ–æ ‡é¢˜
        normalized_title = self._normalize_title(title)
        
        # ç”Ÿæˆå“ˆå¸Œ
        content = f"{normalized_url}::{normalized_title}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _normalize_url(self, url: str) -> str:
        """æ ‡å‡†åŒ–URL"""
        try:
            from urllib.parse import urlparse, urlunparse
            parsed = urlparse(url.lower())
            
            # ç§»é™¤wwwå‰ç¼€
            netloc = parsed.netloc.replace('www.', '')
            
            # ç§»é™¤å°¾éƒ¨æ–œæ 
            path = parsed.path.rstrip('/')
            
            # å¿½ç•¥å¸¸è§çš„è·Ÿè¸ªå‚æ•°
            query = parsed.query
            if query:
                tracking_params = ['utm_source', 'utm_medium', 'utm_campaign', 'utm_term', 'utm_content',
                                 'fbclid', 'gclid', 'ref', 'source', 'from']
                query_parts = []
                for param in query.split('&'):
                    if '=' in param:
                        key, value = param.split('=', 1)
                        if key not in tracking_params:
                            query_parts.append(param)
                query = '&'.join(query_parts)
            
            return urlunparse((parsed.scheme, netloc, path, '', query, ''))
            
        except Exception:
            return url.lower()
    
    def _normalize_title(self, title: str) -> str:
        """æ ‡å‡†åŒ–æ ‡é¢˜"""
        if not title:
            return ""
        
        # å»é™¤HTMLå®ä½“
        title = html.unescape(title)
        
        # åº”ç”¨æ¸…ç†è§„åˆ™
        config = self.classifier.config
        cleaning_rules = config.get("title_cleaning_rules", {})
        
        # æ›¿æ¢è§„åˆ™
        for old, new in cleaning_rules.get("replacements", {}).items():
            title = title.replace(old, new)
        
        # å‰ç¼€æ¸…ç†
        for prefix in cleaning_rules.get("prefixes", []):
            if title.startswith(prefix):
                title = title[len(prefix):].strip()
        
        # åç¼€æ¸…ç†
        for suffix in cleaning_rules.get("suffixes", []):
            if title.endswith(suffix):
                title = title[:-len(suffix)].strip()
        
        return title.strip()
    
    def _is_duplicate(self, bookmark: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤ä¹¦ç­¾"""
        content_hash = self._generate_content_hash(bookmark['url'], bookmark['title'])
        
        if content_hash in self.duplicate_hashes:
            return True
        
        self.duplicate_hashes.add(content_hash)
        return False
    
    def _process_single_bookmark(self, bookmark: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªä¹¦ç­¾"""
        try:
            # æ£€æŸ¥é‡å¤
            if self._is_duplicate(bookmark):
                with self.stats_lock:
                    self.stats.duplicates_removed += 1
                return None
            
            # åˆ†ç±»
            result = self.classifier.classify(
                bookmark['url'], 
                bookmark['title'],
                context={'source_file': bookmark.get('source_file')}
            )
            
            # æ„å»ºç»“æœ
            processed_bookmark = {
                'url': bookmark['url'],
                'title': bookmark['title'],
                'category': result.category,
                'confidence': result.confidence,
                'alternatives': result.alternative_categories,
                'reasoning': result.reasoning,
                'features_used': result.features_used,
                'processing_time': result.processing_time,
                'source_file': bookmark.get('source_file', ''),
                'add_date': bookmark.get('add_date', ''),
                'last_modified': bookmark.get('last_modified', '')
            }
            
            # æ›´æ–°ç»Ÿè®¡
            with self.stats_lock:
                self.stats.processed_bookmarks += 1
                self.stats.categories_found[result.category] = \
                    self.stats.categories_found.get(result.category, 0) + 1
            
            return processed_bookmark
            
        except Exception as e:
            self.logger.error(f"å¤„ç†ä¹¦ç­¾å¤±è´¥ {bookmark.get('url', 'unknown')}: {e}")
            with self.stats_lock:
                self.stats.errors_count += 1
            return None
    
    def process_bookmarks(self, input_files: List[str], show_progress: bool = True) -> List[Dict]:
        """ä¸»å¤„ç†æ–¹æ³• - æ”¯æŒå¹¶è¡Œå¤„ç†"""
        self.logger.info("å¼€å§‹å¤„ç†ä¹¦ç­¾...")
        self.stats.start_time = datetime.now()
        
        # åŠ è½½ä¹¦ç­¾
        all_bookmarks = self.load_bookmarks_from_files(input_files)
        self.stats.total_bookmarks = len(all_bookmarks)
        
        if not all_bookmarks:
            self.logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä¹¦ç­¾")
            return []
        
        # å¹¶è¡Œå¤„ç†
        processed_bookmarks = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_bookmark = {
                executor.submit(self._process_single_bookmark, bookmark): bookmark
                for bookmark in all_bookmarks
            }
            
            # å¤„ç†ç»“æœ
            for future in as_completed(future_to_bookmark):
                try:
                    result = future.result()
                    if result:
                        processed_bookmarks.append(result)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if show_progress and self.stats.processed_bookmarks % 50 == 0:
                        progress = (self.stats.processed_bookmarks + self.stats.duplicates_removed + self.stats.errors_count) / self.stats.total_bookmarks * 100
                        self.logger.info(f"å¤„ç†è¿›åº¦: {progress:.1f}% ({self.stats.processed_bookmarks} å¤„ç†å®Œæˆ, {self.stats.duplicates_removed} é‡å¤, {self.stats.errors_count} é”™è¯¯)")
                        
                except Exception as e:
                    self.logger.error(f"è·å–å¤„ç†ç»“æœæ—¶å‡ºé”™: {e}")
                    with self.stats_lock:
                        self.stats.errors_count += 1
        
        # å®Œæˆç»Ÿè®¡
        self.stats.end_time = datetime.now()
        processing_time = (self.stats.end_time - self.stats.start_time).total_seconds()
        self.stats.processing_speed = len(processed_bookmarks) / processing_time if processing_time > 0 else 0
        self.stats.avg_confidence = sum(b['confidence'] for b in processed_bookmarks) / len(processed_bookmarks) if processed_bookmarks else 0
        
        self.processed_bookmarks = processed_bookmarks
        
        self.logger.info(f"å¤„ç†å®Œæˆ: {len(processed_bookmarks)} ä¸ªä¹¦ç­¾åˆ†ç±»å®Œæˆ")
        self.logger.info(f"å¤„ç†é€Ÿåº¦: {self.stats.processing_speed:.2f} ä¹¦ç­¾/ç§’")
        self.logger.info(f"å¹³å‡ç½®ä¿¡åº¦: {self.stats.avg_confidence:.3f}")
        
        return processed_bookmarks
    
    def organize_bookmarks(self, processed_bookmarks: List[Dict]) -> Dict:
        """ç»„ç»‡ä¹¦ç­¾ä¸ºå±‚æ¬¡ç»“æ„"""
        organized = {}
        
        # è·å–åˆ†ç±»é¡ºåº
        category_order = self.classifier.config.get("category_order", [])
        
        for bookmark in processed_bookmarks:
            category = bookmark['category']
            
            # å¤„ç†åµŒå¥—åˆ†ç±»
            if '/' in category:
                parts = category.split('/')
                current = organized
                
                for i, part in enumerate(parts):
                    if part not in current:
                        current[part] = {} if i < len(parts) - 1 else {'_items': []}
                    if i == len(parts) - 1:
                        if '_items' not in current[part]:
                            current[part]['_items'] = []
                        current[part]['_items'].append(bookmark)
                    else:
                        current = current[part]
            else:
                if category not in organized:
                    organized[category] = {'_items': []}
                organized[category]['_items'].append(bookmark)
        
        # æ’åºä¹¦ç­¾ï¼ˆæŒ‰ç½®ä¿¡åº¦é™åºï¼‰
        def sort_items(node):
            if isinstance(node, dict):
                if '_items' in node:
                    node['_items'].sort(key=lambda x: x['confidence'], reverse=True)
                for key, value in node.items():
                    if key != '_items':
                        sort_items(value)
        
        sort_items(organized)
        
        return organized
    
    def generate_html_output(self, organized_bookmarks: Dict, output_file: str):
        """ç”Ÿæˆå¢å¼ºç‰ˆHTMLè¾“å‡º"""
        self.logger.info(f"ç”ŸæˆHTMLè¾“å‡º: {output_file}")
        
        lines = [
            "<!DOCTYPE NETSCAPE-Bookmark-file-1>",
            "<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=UTF-8\">",
            "<TITLE>Enhanced Bookmark Classification</TITLE>",
            "<H1>ğŸš€ æ™ºèƒ½ä¹¦ç­¾åˆ†ç±»ç³»ç»Ÿ</H1>",
            f"<P>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</P>",
            f"<P>æ€»è®¡: {self.stats.processed_bookmarks} ä¸ªä¹¦ç­¾, å¹³å‡ç½®ä¿¡åº¦: {self.stats.avg_confidence:.3f}</P>",
            "<DL><p>"
        ]
        
        def write_category(name: str, data: Dict, indent: int = 1):
            ind = "    " * indent
            timestamp = str(int(time.time()))
            
            lines.append(f"{ind}<DT><H3 ADD_DATE=\"{timestamp}\">{html.escape(name)}</H3>")
            lines.append(f"{ind}<DL><p>")
            
            # å­åˆ†ç±»
            subcats = sorted([k for k in data.keys() if k != '_items'])
            for subcat in subcats:
                write_category(subcat, data[subcat], indent + 1)
            
            # ä¹¦ç­¾é¡¹ç›®
            if '_items' in data:
                for item in data['_items']:
                    confidence = item['confidence']
                    
                    # ç½®ä¿¡åº¦æŒ‡ç¤ºå™¨
                    if confidence >= 0.9:
                        indicator = "ğŸ”¥"
                    elif confidence >= 0.7:
                        indicator = "ğŸ“Œ"
                    elif confidence >= 0.5:
                        indicator = "â­"
                    else:
                        indicator = "â“"
                    
                    title_with_indicator = f"{indicator} {html.escape(item['title'])}"
                    url_escaped = html.escape(item['url'], quote=True)
                    
                    lines.append(f"{ind}    <DT><A HREF=\"{url_escaped}\" ADD_DATE=\"{timestamp}\">{title_with_indicator}</A>")
            
            lines.append(f"{ind}</DL><p>")
        
        # æŒ‰é…ç½®çš„é¡ºåºå¤„ç†åˆ†ç±»
        category_order = self.classifier.config.get("category_order", [])
        
        for category in category_order:
            if category in organized_bookmarks:
                write_category(category, organized_bookmarks[category])
        
        # å¤„ç†å…¶ä»–åˆ†ç±»
        for category in sorted(organized_bookmarks.keys()):
            if category not in category_order:
                write_category(category, organized_bookmarks[category])
        
        lines.append("</DL><p>")
        
        # å†™å…¥æ–‡ä»¶
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        self.logger.info(f"HTMLæ–‡ä»¶å·²ä¿å­˜: {output_file}")
    
    def generate_markdown_output(self, organized_bookmarks: Dict, output_file: str):
        """ç”Ÿæˆå¢å¼ºç‰ˆMarkdownè¾“å‡º"""
        self.logger.info(f"ç”ŸæˆMarkdownè¾“å‡º: {output_file}")
        
        lines = [
            "# ğŸš€ æ™ºèƒ½ä¹¦ç­¾åˆ†ç±»æŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  ",
            f"**å¤„ç†ç»Ÿè®¡**: {self.stats.processed_bookmarks} ä¸ªä¹¦ç­¾, å¹³å‡ç½®ä¿¡åº¦: {self.stats.avg_confidence:.3f}  ",
            f"**å¤„ç†é€Ÿåº¦**: {self.stats.processing_speed:.2f} ä¹¦ç­¾/ç§’  ",
            f"**å»é™¤é‡å¤**: {self.stats.duplicates_removed} ä¸ª",
            "",
            "## ğŸ“Š åˆ†ç±»ç»Ÿè®¡",
            ""
        ]
        
        # åˆ†ç±»ç»Ÿè®¡
        for category, count in sorted(self.stats.categories_found.items(), key=lambda x: x[1], reverse=True):
            lines.append(f"- **{category}**: {count} ä¸ª")
        
        lines.extend(["", "---", ""])
        
        def write_category(name: str, data: Dict, level: int = 2):
            prefix = "#" * min(level, 6)
            lines.append(f"{prefix} {name}")
            lines.append("")
            
            # å­åˆ†ç±»
            subcats = sorted([k for k in data.keys() if k != '_items'])
            for subcat in subcats:
                write_category(subcat, data[subcat], level + 1)
            
            # ä¹¦ç­¾é¡¹ç›®
            if '_items' in data:
                for item in data['_items']:
                    confidence = item['confidence']
                    
                    # ç½®ä¿¡åº¦æŒ‡ç¤ºå™¨
                    if confidence >= 0.9:
                        indicator = "ğŸ”¥"
                    elif confidence >= 0.7:
                        indicator = "ğŸ“Œ"
                    elif confidence >= 0.5:
                        indicator = "â­"
                    else:
                        indicator = "â“"
                    
                    lines.append(f"- {indicator} [{item['title']}]({item['url']}) *({confidence:.3f})*")
                
                lines.append("")
        
        # æŒ‰é¡ºåºå¤„ç†åˆ†ç±»
        category_order = self.classifier.config.get("category_order", [])
        
        for category in category_order:
            if category in organized_bookmarks:
                write_category(category, organized_bookmarks[category])
        
        for category in sorted(organized_bookmarks.keys()):
            if category not in category_order:
                write_category(category, organized_bookmarks[category])
        
        # æ·»åŠ è¯¦ç»†ç»Ÿè®¡
        lines.extend([
            "## ğŸ“ˆ å¤„ç†è¯¦æƒ…",
            "",
            f"- **æ€»ä¹¦ç­¾æ•°**: {self.stats.total_bookmarks}",
            f"- **æˆåŠŸå¤„ç†**: {self.stats.processed_bookmarks}",
            f"- **é‡å¤ç§»é™¤**: {self.stats.duplicates_removed}",
            f"- **å¤„ç†é”™è¯¯**: {self.stats.errors_count}",
            f"- **å¤„ç†æ—¶é—´**: {(self.stats.end_time - self.stats.start_time).total_seconds():.2f} ç§’",
            f"- **ç¼“å­˜å‘½ä¸­**: {self.classifier.get_stats().get('cache_hits', 0)}",
            ""
        ])
        
        # å†™å…¥æ–‡ä»¶
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        self.logger.info(f"Markdownæ–‡ä»¶å·²ä¿å­˜: {output_file}")
    
    def generate_json_report(self, organized_bookmarks: Dict, output_file: str):
        """ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        self.logger.info(f"ç”ŸæˆJSONæŠ¥å‘Š: {output_file}")
        
        report = {
            "metadata": {
                "generation_time": datetime.now().isoformat(),
                "processor_version": "2.0.0",
                "config_file": self.config_file
            },
            "statistics": {
                "total_bookmarks": self.stats.total_bookmarks,
                "processed_bookmarks": self.stats.processed_bookmarks,
                "duplicates_removed": self.stats.duplicates_removed,
                "errors_count": self.stats.errors_count,
                "processing_time_seconds": (self.stats.end_time - self.stats.start_time).total_seconds(),
                "processing_speed": self.stats.processing_speed,
                "average_confidence": self.stats.avg_confidence,
                "category_distribution": dict(self.stats.categories_found)
            },
            "classifier_stats": self.classifier.get_stats(),
            "bookmarks": organized_bookmarks,
            "low_confidence_items": [
                {
                    "url": item['url'],
                    "title": item['title'],
                    "category": item['category'],
                    "confidence": item['confidence'],
                    "alternatives": item['alternatives'][:3]
                }
                for item in self.processed_bookmarks
                if item['confidence'] < 0.6
            ]
        }
        
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"JSONæŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    
    def save_learning_data(self):
        """ä¿å­˜å­¦ä¹ æ•°æ®"""
        self.classifier.save_learning_data()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¢å¼ºç‰ˆä¹¦ç­¾åˆ†ç±»å¤„ç†ç³»ç»Ÿ",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    parser.add_argument('-i', '--input', nargs='+', default=[], help='è¾“å…¥çš„HTMLä¹¦ç­¾æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-c', '--config', default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output-dir', default='tests/output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--html-output', default='bookmarks_enhanced.html', help='HTMLè¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--md-output', default='bookmarks_enhanced.md', help='Markdownè¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--json-output', default='bookmarks_report.json', help='JSONæŠ¥å‘Šæ–‡ä»¶å')
    parser.add_argument('--workers', type=int, default=4, help='å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°')
    parser.add_argument('--no-progress', action='store_true', help='ä¸æ˜¾ç¤ºå¤„ç†è¿›åº¦')
    parser.add_argument('--save-learning', action='store_true', help='ä¿å­˜å­¦ä¹ æ•°æ®')
    
    args = parser.parse_args()
    
    # è·å–è¾“å…¥æ–‡ä»¶
    input_files = args.input if args.input else glob.glob('tests/input/*.html')
    
    if not input_files:
        if os.path.exists('bookmarks_2025_7_1.html'):
            input_files = ['bookmarks_2025_7_1.html']
        else:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶")
            print("è¯·å°†ä¹¦ç­¾æ–‡ä»¶æ”¾åœ¨ tests/input/ ç›®å½•ä¸‹ï¼Œæˆ–ä½¿ç”¨ -i å‚æ•°æŒ‡å®šæ–‡ä»¶")
            return
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†ä¹¦ç­¾æ–‡ä»¶: {input_files}")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print(f"âš¡ å¹¶è¡Œçº¿ç¨‹æ•°: {args.workers}")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = EnhancedBookmarkProcessor(args.config, args.workers)
    
    try:
        # å¤„ç†ä¹¦ç­¾
        processed_bookmarks = processor.process_bookmarks(
            input_files, 
            show_progress=not args.no_progress
        )
        
        if not processed_bookmarks:
            print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ä¹¦ç­¾")
            return
        
        # ç»„ç»‡ä¹¦ç­¾
        organized_bookmarks = processor.organize_bookmarks(processed_bookmarks)
        
        # ç”Ÿæˆè¾“å‡º
        os.makedirs(args.output_dir, exist_ok=True)
        
        html_path = os.path.join(args.output_dir, args.html_output)
        md_path = os.path.join(args.output_dir, args.md_output)
        json_path = os.path.join(args.output_dir, args.json_output)
        
        processor.generate_html_output(organized_bookmarks, html_path)
        processor.generate_markdown_output(organized_bookmarks, md_path)
        processor.generate_json_report(organized_bookmarks, json_path)
        
        # ä¿å­˜å­¦ä¹ æ•°æ®
        if args.save_learning:
            processor.save_learning_data()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        stats = processor.stats
        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"ğŸ“ˆ æ€»è®¡: {stats.total_bookmarks} ä¸ªä¹¦ç­¾")
        print(f"âœ¨ æˆåŠŸå¤„ç†: {stats.processed_bookmarks} ä¸ª")
        print(f"ğŸ”„ å»é™¤é‡å¤: {stats.duplicates_removed} ä¸ª")
        print(f"âŒ å¤„ç†é”™è¯¯: {stats.errors_count} ä¸ª")
        print(f"âš¡ å¤„ç†é€Ÿåº¦: {stats.processing_speed:.2f} ä¹¦ç­¾/ç§’")
        print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {stats.avg_confidence:.3f}")
        print(f"ğŸ’¾ è¾“å‡ºä¿å­˜è‡³: {args.output_dir}")
        
        # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
        print(f"\nğŸ“Š åˆ†ç±»åˆ†å¸ƒ:")
        for category, count in sorted(stats.categories_found.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  - {category}: {count} ä¸ª")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logging.exception("å¤„ç†é”™è¯¯è¯¦æƒ…:")

if __name__ == "__main__":
    main()