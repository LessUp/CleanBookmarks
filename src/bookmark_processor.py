"""
Bookmark Processor - ä¹¦ç­¾å¤„ç†å™¨

è´Ÿè´£æ‰¹é‡å¤„ç†ä¹¦ç­¾æ–‡ä»¶ï¼Œåè°ƒå„ä¸ªç»„ä»¶å®Œæˆæ•´ä¸ªåˆ†ç±»æµç¨‹
"""

import json
import logging
import os
import time
from typing import List, Dict, Optional, Tuple
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

from bs4 import BeautifulSoup
from .ai_classifier import AIBookmarkClassifier

# å¯¼å…¥å ä½ç¬¦æ¨¡å—
from .placeholder_modules import (
    DataExporter, BookmarkDeduplicator, HealthChecker
)

class BookmarkProcessor:
    """ä¹¦ç­¾å¤„ç†å™¨ä¸»ç±»"""
    
    def __init__(self, config_path: str = "config.json", max_workers: int = 4, use_ml: bool = True):
        self.config_path = config_path
        # ä¼˜åŒ–çº¿ç¨‹æ± å¤§å°ï¼šé™åˆ¶æœ€å¤§çº¿ç¨‹æ•°é¿å…è¿‡åº¦ç«äº‰
        self.max_workers = min(max_workers, 32)  # é™åˆ¶æœ€å¤§32çº¿ç¨‹
        self.use_ml = use_ml
        
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            self.logger.error(f"æ— æ³•åŠ è½½æˆ–è§£æé…ç½®æ–‡ä»¶ {config_path}: {e}")
            self.config = {}

        # å»¶è¿Ÿåˆå§‹åŒ–ç»„ä»¶ä»¥é¿å…å¯åŠ¨å¼€é”€
        self._classifier = None
        self._deduplicator = None
        self._health_checker = None
        self._exporter = None
        
        # ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–
        self._classification_cache = {}
        self._url_validation_cache = {}
        
        # å¤„ç†ç»Ÿè®¡
        self.stats = {
            'total_bookmarks': 0,
            'processed_bookmarks': 0,
            'duplicates_removed': 0,
            'errors': 0,
            'processing_time': 0.0,
            'categories_found': {},
            'files_processed': 0
        }
    
    @property
    def classifier(self):
        """Lazy loading classifier"""
        if self._classifier is None:
            self._classifier = AIBookmarkClassifier(self.config_path, enable_ml=self.use_ml)
        return self._classifier
    
    @property
    def deduplicator(self):
        """Lazy loading deduplicator"""
        if self._deduplicator is None:
            from .placeholder_modules import BookmarkDeduplicator
            self._deduplicator = BookmarkDeduplicator()
        return self._deduplicator
    
    @property
    def health_checker(self):
        """Lazy loading health checker"""
        if self._health_checker is None:
            from .placeholder_modules import HealthChecker
            self._health_checker = HealthChecker()
        return self._health_checker
    
    @property
    def exporter(self):
        """Lazy loading exporter"""
        if self._exporter is None:
            from .placeholder_modules import DataExporter
            self._exporter = DataExporter(config=self.config)
        return self._exporter
    
    def process_files(self, input_files: List[str], output_dir: str = "output", 
                     train_models: bool = False) -> Dict:
        """å¤„ç†å¤šä¸ªä¹¦ç­¾æ–‡ä»¶"""
        start_time = time.time()
        
        self.logger.info(f"å¼€å§‹å¤„ç† {len(input_files)} ä¸ªæ–‡ä»¶")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # å¹¶è¡ŒåŠ è½½æ‰€æœ‰ä¹¦ç­¾ä»¥åŠ é€ŸIOæ“ä½œ
        all_bookmarks = []
        with ThreadPoolExecutor(max_workers=min(len(input_files), 8)) as file_executor:
            file_futures = {file_executor.submit(self._load_bookmarks_from_file, file_path): file_path 
                          for file_path in input_files}
            
            for future in as_completed(file_futures):
                file_path = file_futures[future]
                try:
                    bookmarks = future.result()
                    all_bookmarks.extend(bookmarks)
                    self.stats['files_processed'] += 1
                except Exception as e:
                    self.logger.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                    self.stats['errors'] += 1
        
        self.stats['total_bookmarks'] = len(all_bookmarks)
        
        if not all_bookmarks:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä¹¦ç­¾")
            return self.stats
        
        # ä¼˜åŒ–å»é‡å¤„ç†ï¼šå…ˆè¿›è¡Œå¿«é€ŸURLå»é‡
        self.logger.info("å¼€å§‹å¿«é€Ÿå»é‡å¤„ç†...")
        # å¿«é€ŸURLå»é‡
        seen_urls = set()
        fast_unique = []
        for bookmark in all_bookmarks:
            url = bookmark.get('url', '')
            if url not in seen_urls:
                seen_urls.add(url)
                fast_unique.append(bookmark)
        
        fast_duplicates_removed = len(all_bookmarks) - len(fast_unique)
        self.logger.info(f"å¿«é€Ÿå»é‡ç§»é™¤äº† {fast_duplicates_removed} ä¸ªé‡å¤ä¹¦ç­¾")
        
        # å¯¹å‰©ä½™ä¹¦ç­¾è¿›è¡Œé«˜çº§å»é‡
        if len(fast_unique) > 1000:  # åªå¯¹å¤§é‡ä¹¦ç­¾è¿›è¡Œé«˜çº§å»é‡
            unique_bookmarks, duplicates = self.deduplicator.remove_duplicates(fast_unique)
            self.stats['duplicates_removed'] = fast_duplicates_removed + len(duplicates)
        else:
            unique_bookmarks = fast_unique
            self.stats['duplicates_removed'] = fast_duplicates_removed
        
        # å¹¶è¡Œåˆ†ç±»å¤„ç†
        self.logger.info(f"å¼€å§‹åˆ†ç±» {len(unique_bookmarks)} ä¸ªä¹¦ç­¾...")
        classified_bookmarks = self._classify_bookmarks_parallel(unique_bookmarks)
        
        # ç»„ç»‡åˆ†ç±»ç»“æœ
        organized_bookmarks = self._organize_bookmarks(classified_bookmarks)
        
        # å¯¼å‡ºç»“æœ
        self._export_results(organized_bookmarks, output_dir)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if train_models and self.use_ml:
            self._train_models(classified_bookmarks)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['processing_time'] = time.time() - start_time
        self.stats['processed_bookmarks'] = len(classified_bookmarks)
        
        self.logger.info(f"å¤„ç†å®Œæˆ: {self.stats['processed_bookmarks']} ä¸ªä¹¦ç­¾å·²åˆ†ç±»")
        
        return self.stats
    
    def _load_bookmarks_from_file(self, file_path: str) -> List[Dict]:
        """ä¼˜åŒ–çš„ä»HTMLæ–‡ä»¶åŠ è½½ä¹¦ç­¾"""
        bookmarks = []
        
        try:
            # ä½¿ç”¨æ›´å¿«çš„è§£æå™¨
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ä½¿ç”¨lxmlè§£æå™¨å¦‚æœå¯ç”¨ï¼Œå¦åˆ™ä½¿ç”¨html.parser
            try:
                soup = BeautifulSoup(content, 'lxml')
            except:
                soup = BeautifulSoup(content, 'html.parser')
            
            links = soup.find_all('a', href=True)  # åªæŸ¥æ‰¾æœ‰hrefçš„é“¾æ¥
            
            for link in links:
                url = link.get('href', '').strip()
                title = (link.string or link.get_text() or '').strip()
                
                if url and title and self._is_valid_url(url):
                    bookmarks.append({
                        'url': url,
                        'title': title,
                        'source_file': file_path,
                        'add_date': link.get('add_date', ''),
                        'last_modified': link.get('last_modified', '')
                    })
            
            self.logger.info(f"ä» {file_path} åŠ è½½äº† {len(bookmarks)} ä¸ªä¹¦ç­¾")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            self.stats['errors'] += 1
        
        return bookmarks
    
    def _is_valid_url(self, url: str) -> bool:
        """éªŒè¯URLæœ‰æ•ˆæ€§"""
        if not url:
            return False
        
        # è¿‡æ»¤æ— æ•ˆURL
        invalid_prefixes = ['javascript:', 'data:', 'chrome:', 'about:', 'file:', 'mailto:']
        for prefix in invalid_prefixes:
            if url.lower().startswith(prefix):
                return False
        
        return url.startswith(('http://', 'https://'))
    
    def _classify_bookmarks_parallel(self, bookmarks: List[Dict]) -> List[Dict]:
        """ä¼˜åŒ–çš„å¹¶è¡Œåˆ†ç±»ä¹¦ç­¾"""
        classified_bookmarks = []
        batch_size = 100  # æ‰¹å¤„ç†å¤§å°
        
        # åˆ†æ‰¹å¤„ç†ä»¥å‡å°‘å†…å­˜ä½¿ç”¨å’Œæé«˜æ•ˆç‡
        for i in range(0, len(bookmarks), batch_size):
            batch = bookmarks[i:i + batch_size]
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤åˆ†ç±»ä»»åŠ¡
                future_to_bookmark = {
                    executor.submit(self._classify_single_bookmark_cached, bookmark): bookmark
                    for bookmark in batch
                }
                
                # æ”¶é›†ç»“æœ
                batch_results = []
                for future in as_completed(future_to_bookmark):
                    bookmark = future_to_bookmark[future]
                    
                    try:
                        result = future.result(timeout=30)  # æ·»åŠ è¶…æ—¶
                        if result:
                            batch_results.append(result)
                            
                    except Exception as e:
                        self.logger.error(f"åˆ†ç±»å¤±è´¥ {bookmark.get('url', 'unknown')}: {e}")
                        self.stats['errors'] += 1
                
                classified_bookmarks.extend(batch_results)
                
                # æ˜¾ç¤ºè¿›åº¦
                completed = i + len(batch)
                progress = min(completed / len(bookmarks) * 100, 100)
                self.logger.info(f"åˆ†ç±»è¿›åº¦: {progress:.1f}% ({completed}/{len(bookmarks)})")
        
        return classified_bookmarks
    
    def _classify_single_bookmark_cached(self, bookmark: Dict) -> Optional[Dict]:
        """å¸¦ç¼“å­˜çš„å•ä¸ªä¹¦ç­¾åˆ†ç±»"""
        try:
            url = bookmark['url']
            title = bookmark['title']
            
            # åˆ›å»ºç¼“å­˜é”®
            cache_key = f"{url}|{title}"
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self._classification_cache:
                cached_result = self._classification_cache[cache_key]
                return {
                    **bookmark,
                    **cached_result
                }
            
            # ä½¿ç”¨AIåˆ†ç±»å™¨
            result = self.classifier.classify(url, title)
            
            # å¤„ç†åˆ†ç±»ç»“æœï¼ˆå¯èƒ½æ˜¯å¯¹è±¡æˆ–å­—å…¸ï¼‰
            if hasattr(result, 'category'):
                # ClassificationResultå¯¹è±¡
                cached_data = {
                    'category': result.category,
                    'subcategory': result.subcategory if hasattr(result, 'subcategory') else None,
                    'confidence': result.confidence,
                    'alternatives': result.alternatives if hasattr(result, 'alternatives') else [],
                    'reasoning': result.reasoning if hasattr(result, 'reasoning') else [],
                    'method': result.method if hasattr(result, 'method') else 'unknown',
                    'processing_time': result.processing_time if hasattr(result, 'processing_time') else 0.0
                }
            else:
                # å­—å…¸ç»“æœ
                cached_data = {
                    'category': result.get('category', 'æœªåˆ†ç±»'),
                    'subcategory': result.get('subcategory'),
                    'confidence': result.get('confidence', 0.0),
                    'alternatives': result.get('alternatives', []),
                    'reasoning': result.get('reasoning', []),
                    'method': result.get('method', 'unknown'),
                    'processing_time': result.get('processing_time', 0.0)
                }
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self._classification_cache) < 10000:
                self._classification_cache[cache_key] = cached_data
            
            # æ„å»ºç»“æœ
            classified_bookmark = {
                **bookmark,
                **cached_data
            }
            
            # æ›´æ–°åˆ†ç±»ç»Ÿè®¡
            category = cached_data['category']
            self.stats['categories_found'][category] = self.stats['categories_found'].get(category, 0) + 1
            
            return classified_bookmark
            
        except Exception as e:
            self.logger.error(f"å•ä¸ªä¹¦ç­¾åˆ†ç±»å¤±è´¥: {e}")
            return None
    
    def _organize_bookmarks(self, classified_bookmarks: List[Dict]) -> Dict:
        """ç»„ç»‡ä¹¦ç­¾ä¸ºå±‚æ¬¡ç»“æ„"""
        organized = {}
        
        # åˆ†ç±»åç§°æ ‡å‡†åŒ–æ˜ å°„
        category_mapping = {
            'AI': 'ğŸ¤– AI',
            'AI/æ¨¡å‹ä¸å¹³å°': 'ğŸ¤– AI/æ¨¡å‹å¹³å°',
            'AI/åº”ç”¨ä¸å·¥å…·': 'ğŸ¤– AI/åº”ç”¨å·¥å…·', 
            'AI/è®ºæ–‡ä¸èµ„è®¯': 'ğŸ¤– AI/è®ºæ–‡èµ„è®¯',
            'æŠ€æœ¯æ ˆ': 'ğŸ’» ç¼–ç¨‹',
            'æŠ€æœ¯æ ˆ/ä»£ç  & å¼€æº': 'ğŸ’» ç¼–ç¨‹/ä»£ç ä»“åº“',
            'æŠ€æœ¯æ ˆ/ç¼–ç¨‹è¯­è¨€': 'ğŸ’» ç¼–ç¨‹/ç¼–ç¨‹è¯­è¨€',
            'æŠ€æœ¯æ ˆ/Webå¼€å‘': 'ğŸ’» ç¼–ç¨‹/Webå¼€å‘',
            'æŠ€æœ¯æ ˆ/äº‘æœåŠ¡ & DevOps': 'ğŸ’» ç¼–ç¨‹/DevOpsè¿ç»´',
            'Books': 'ğŸ“š å­¦ä¹ /ä¹¦ç±æ‰‹å†Œ',
            'æŠ€æœ¯èµ„æ–™': 'ğŸ“š å­¦ä¹ /æŠ€æœ¯æ–‡æ¡£',
            'Lectures': 'ğŸ“š å­¦ä¹ /è¯¾ç¨‹è®²åº§',
            'ç¤¾åŒº': 'ğŸ‘¥ ç¤¾åŒº',
            'èµ„è®¯': 'ğŸ“° èµ„è®¯',
            'Utils': 'ğŸ› ï¸ å·¥å…·',
            'å¨±ä¹': 'ğŸ® å¨±ä¹',
            'æ±‚èŒ': 'ğŸ’¼ æ±‚èŒ',
            'æœªåˆ†ç±»': 'ğŸ“‚ å…¶ä»–',
            'æ–°é—»/èµ„è®¯': 'ğŸ“° èµ„è®¯',
            'æŠ€æœ¯/ç¼–ç¨‹': 'ğŸ’» ç¼–ç¨‹',
            'å­¦ä¹ ': 'ğŸ“š å­¦ä¹ ',
            'ç”Ÿç‰©ä¿¡æ¯': 'ğŸ§¬ ç”Ÿç‰©',
            'äººå·¥æ™ºèƒ½': 'ğŸ¤– AI',
            'ç¼–ç¨‹å¼€å‘': 'ğŸ’» ç¼–ç¨‹',
            'å­¦ä¹ èµ„æ–™': 'ğŸ“š å­¦ä¹ ',
            'æŠ€æœ¯ç¤¾åŒº': 'ğŸ‘¥ ç¤¾åŒº',
            'èµ„è®¯åª’ä½“': 'ğŸ“° èµ„è®¯',
            'å®ç”¨å·¥å…·': 'ğŸ› ï¸ å·¥å…·',
            'å¨±ä¹ä¼‘é—²': 'ğŸ® å¨±ä¹',
            'ç¨åé˜…è¯»': 'ğŸ“– ç¨è¯»',
            'æ±‚èŒæ‹›è˜': 'ğŸ’¼ æ±‚èŒ',
            'å…¶ä»–åˆ†ç±»': 'ğŸ“‚ å…¶ä»–',
        }
        
        for bookmark in classified_bookmarks:
            category = bookmark['category']
            subcategory = bookmark.get('subcategory')
            
            # æ ‡å‡†åŒ–åˆ†ç±»åç§°
            category = category_mapping.get(category, category)
            
            # å¤„ç†å¸¦æ–œæ çš„åˆ†ç±»åç§°ï¼ˆå¦‚AI/æ¨¡å‹ä¸å¹³å°ï¼‰
            if '/' in category:
                parts = category.split('/', 1)
                main_category = parts[0].strip()
                sub_category = parts[1].strip()
                
                # åˆ›å»ºä¸»åˆ†ç±»
                if main_category not in organized:
                    organized[main_category] = {'_items': [], '_subcategories': {}}
                
                # åˆ›å»ºå­åˆ†ç±»
                if sub_category not in organized[main_category]['_subcategories']:
                    organized[main_category]['_subcategories'][sub_category] = {'_items': []}
                
                organized[main_category]['_subcategories'][sub_category]['_items'].append(bookmark)
            else:
                # å¤„ç†ä¼ ç»Ÿçš„å•å±‚åˆ†ç±»
                if category not in organized:
                    organized[category] = {'_items': [], '_subcategories': {}}
                
                if subcategory:
                    if subcategory not in organized[category]['_subcategories']:
                        organized[category]['_subcategories'][subcategory] = {'_items': []}
                    organized[category]['_subcategories'][subcategory]['_items'].append(bookmark)
                else:
                    organized[category]['_items'].append(bookmark)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        for category_data in organized.values():
            category_data['_items'].sort(key=lambda x: x['confidence'], reverse=True)
            
            for subcat_data in category_data['_subcategories'].values():
                subcat_data['_items'].sort(key=lambda x: x['confidence'], reverse=True)
        
        return organized
    
    def _export_results(self, organized_bookmarks: Dict, output_dir: str):
        """ä¼˜åŒ–çš„å¯¼å‡ºå¤„ç†ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å¹¶è¡Œå¯¼å‡ºå¤šç§æ ¼å¼ä»¥èŠ‚çœæ—¶é—´
        export_tasks = [
            ('html', f"bookmarks_{timestamp}.html"),
            ('json', f"bookmarks_{timestamp}.json"),
            ('markdown', f"report_{timestamp}.md")
        ]
        
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            
            for format_type, filename in export_tasks:
                output_file = os.path.join(output_dir, filename)
                
                if format_type == 'html':
                    future = executor.submit(self.exporter.export_html, organized_bookmarks, output_file)
                elif format_type == 'json':
                    future = executor.submit(self.exporter.export_json, organized_bookmarks, output_file, self.stats)
                elif format_type == 'markdown':
                    future = executor.submit(self.exporter.export_markdown, organized_bookmarks, output_file, self.stats)
                
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰å¯¼å‡ºå®Œæˆ
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    self.logger.error(f"å¯¼å‡ºå¤±è´¥: {e}")
        
        self.logger.info(f"ç»“æœå·²å¯¼å‡ºåˆ°: {output_dir}")
    
    def _train_models(self, classified_bookmarks: List[Dict]):
        """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
        if not self.classifier.ml_classifier:
            self.logger.warning("æœºå™¨å­¦ä¹ ç»„ä»¶æœªå¯ç”¨ï¼Œè·³è¿‡è®­ç»ƒ")
            return
        
        self.logger.info("å¼€å§‹è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        training_data = []
        labels = []
        
        for bookmark in classified_bookmarks:
            if bookmark['confidence'] > 0.8:  # åªä½¿ç”¨é«˜ç½®ä¿¡åº¦çš„æ•°æ®è®­ç»ƒ
                features = self.classifier.extract_features(bookmark['url'], bookmark['title'])
                training_data.append(features)
                labels.append(bookmark['category'])
        
        if len(training_data) > 50:  # éœ€è¦è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®
            self.classifier.ml_classifier.train(training_data, labels)
            self.logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä½¿ç”¨äº† {len(training_data)} ä¸ªæ ·æœ¬")
        else:
            self.logger.warning(f"è®­ç»ƒæ•°æ®ä¸è¶³ ({len(training_data)} ä¸ªæ ·æœ¬)ï¼Œè·³è¿‡è®­ç»ƒ")
    
    def health_check(self, bookmarks: List[Dict]) -> Dict:
        """å¯¹ä¹¦ç­¾è¿›è¡Œå¥åº·æ£€æŸ¥"""
        self.logger.info(f"å¼€å§‹å¥åº·æ£€æŸ¥ {len(bookmarks)} ä¸ªä¹¦ç­¾...")
        
        results = self.health_checker.check_bookmarks(bookmarks)
        summary = self.health_checker.get_summary(results)
        
        self.logger.info(f"å¥åº·æ£€æŸ¥å®Œæˆ: {summary['accessible_count']}/{summary['total_count']} ä¸ªé“¾æ¥å¯è®¿é—®")
        
        return summary
    
    def get_statistics(self) -> Dict:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        classifier_stats = self.classifier.get_statistics()
        
        return {
            **self.stats,
            'classifier_stats': classifier_stats,
            'processing_speed': self.stats['processed_bookmarks'] / max(self.stats['processing_time'], 0.001),
            'success_rate': (self.stats['processed_bookmarks'] / max(self.stats['total_bookmarks'], 1)) * 100,
            'average_confidence': classifier_stats.get('average_confidence', 0.0)
        }