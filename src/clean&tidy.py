"""
ä¸€ä¸ªç”¨äºæ¸…ç†å’Œåˆ†ç±»æµè§ˆå™¨ä¹¦ç­¾çš„ Python è„šæœ¬ã€‚

è¯¥è„šæœ¬ä¼šè¯»å–ä¸€ä¸ª HTML æ ¼å¼çš„ä¹¦ç­¾æ–‡ä»¶ï¼Œæ ¹æ®é¢„å®šä¹‰çš„è§„åˆ™å¯¹ä¹¦ç­¾è¿›è¡Œåˆ†ç±»å’Œå»é‡ï¼Œ
ç„¶åç”Ÿæˆä¸€ä¸ªæ¸…ç†è¿‡çš„ã€å¯é‡æ–°å¯¼å…¥æµè§ˆå™¨çš„ HTML æ–‡ä»¶ï¼Œä»¥åŠä¸€ä¸ª Markdown æ ¼å¼çš„çº¯é“¾æ¥åˆ—è¡¨ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- åŸºäºå…³é”®è¯å¯¹ä¹¦ç­¾è¿›è¡Œå¤šçº§åˆ†ç±»ã€‚
- è‡ªåŠ¨ä¸ºç‰¹å®šåˆ†ç±»ï¼ˆå¦‚ GitHubï¼‰åˆ›å»ºæ›´æ·±å±‚æ¬¡çš„ç›®å½•ç»“æ„ã€‚
- æ¸…ç† URLï¼Œå»é™¤è·Ÿè¸ªå‚æ•°ã€‚
- å¯¹æ¸…ç†åçš„ URLè¿›è¡Œå»é‡ã€‚
- æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼Œå¯è‡ªå®šä¹‰è¾“å…¥/è¾“å‡ºæ–‡ä»¶ã€‚
"""
import os
import argparse
import json
import glob
from bs4 import BeautifulSoup, Doctype
import time
from urllib.parse import urlparse
from collections import Counter
from functools import lru_cache

@lru_cache(maxsize=200_000)
def _parse_url_cached(url: str):
    """å¸¦ LRU ç¼“å­˜çš„ urlparseï¼ŒåŠ é€Ÿé‡å¤è§£æ"""
    return urlparse(url)


def clean_url(raw_url: str) -> str:
    """å»é™¤æŸ¥è¯¢å‚æ•°ä¸é”šç‚¹ï¼Œè¿”å›å‡€åŒ–åçš„ URL"""
    if not raw_url:
        return ""
    parts = _parse_url_cached(raw_url)
    cleaned = f"{parts.scheme}://{parts.netloc}{parts.path}"
    return cleaned.rstrip("/")


def clean_title(title, config):
    """æ ¹æ®é…ç½®æ¸…ç†ä¹¦ç­¾æ ‡é¢˜"""
    # å¦‚æœæ²¡æœ‰é…ç½®è§„åˆ™ï¼Œç›´æ¥è¿”å›åŸæ ‡é¢˜
    cleaning_rules = config.get("title_cleaning_rules")
    if not cleaning_rules:
        return title

    # 1. ç§»é™¤å‰ç¼€
    for prefix in cleaning_rules.get("prefixes", []):
        if title.startswith(prefix):
            title = title[len(prefix):].lstrip()

    # 2. ç§»é™¤åç¼€
    for suffix in cleaning_rules.get("suffixes", []):
        if title.endswith(suffix):
            title = title[:-len(suffix)].rstrip()

    # 3. æ‰§è¡Œæ›¿æ¢
    for old, new in cleaning_rules.get("replacements", {}).items():
        title = title.replace(old, new)

    return title.strip()


def classify_bookmark(url, title, seen_urls, config):
    """
    æ ¹æ®é…ç½®æ–‡ä»¶çš„è§„åˆ™å¯¹å•ä¸ªä¹¦ç­¾è¿›è¡Œåˆ†ç±»ã€‚
    è¿™æ˜¯ä¸€ä¸ªé‡‡ç”¨"å…¨å±€è¯„åˆ†æ¨¡å‹"çš„ã€å®Œå…¨ç”±é…ç½®é©±åŠ¨çš„é€šç”¨åˆ†ç±»å¼•æ“ã€‚
    æ‰€æœ‰è§„åˆ™éƒ½ä¼šä¸ºå¯èƒ½çš„åˆ†ç±»è´¡çŒ®åˆ†æ•°ï¼Œæœ€ç»ˆé€‰æ‹©å¾—åˆ†æœ€é«˜çš„åˆ†ç±»ã€‚

    Args:
        url (str): ä¹¦ç­¾çš„ URLã€‚
        title (str): ä¹¦ç­¾çš„æ ‡é¢˜ã€‚
        seen_urls (set): ç”¨äºè®°å½•å·²å¤„ç†è¿‡çš„ URLï¼Œä»¥å®ç°å»é‡ã€‚
        config (dict): ä» config.json åŠ è½½çš„å®Œæ•´é…ç½®å¯¹è±¡ã€‚

    Returns:
        tuple or None: å¦‚æœä¹¦ç­¾æ˜¯å”¯ä¸€çš„ï¼Œåˆ™è¿”å›ä¸€ä¸ªå…ƒç»„ï¼Œ
                       ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åˆ†ç±»è·¯å¾„ï¼ˆå­—ç¬¦ä¸²æˆ–å…ƒç»„ï¼‰ï¼Œ
                       ç¬¬äºŒä¸ªå…ƒç´ æ˜¯ (URL, æ ‡é¢˜) å…ƒç»„ã€‚
                       å¦‚æœä¹¦ç­¾é‡å¤æˆ–æ— æœ‰æ•ˆåˆ†ç±»ï¼Œåˆ™è¿”å› (None, None)ã€‚
    """
    if not url:
        return None, None

    cleaned_url = clean_url(url)
    if cleaned_url in seen_urls:
        return None, None
    seen_urls.add(cleaned_url)

    lower_title = title.lower()
    parsed = _parse_url_cached(url)
    domain = parsed.netloc.lower()
    path_parts = [p for p in parsed.path.split("/") if p]
    
    # åˆå§‹åŒ–æ‰€æœ‰å¯èƒ½åˆ†ç±»çš„åˆ†æ•°
    scores = {}
    
    # æŒ‰ç…§ processing_order ä¸­å®šä¹‰çš„é¡ºåºæ‰§è¡Œè®¡åˆ†
    for rule_type in config.get("processing_order", []):
        
        # --- 1. ç‰¹æ®ŠåŸŸåè§„åˆ™å¤„ç†å™¨ ---
        if rule_type == "special_domain_rules":
            rules = config.get("special_domain_rules", {})
            for category_path_str, rule in rules.items():
                category_path = tuple(category_path_str.split('/'))
                weight = rule.get("weight", 5) # åŸŸååŒ¹é…æƒé‡è¾ƒé«˜
                if any(d in domain for d in rule.get("domains", [])):
                    scores.setdefault(category_path, 0)
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æŒ‰è·¯å¾„åˆ†å‰²
                    if "split_by_path_segment" in rule and path_parts:
                        segment_index = rule["split_by_path_segment"] - 1
                        if segment_index < len(path_parts):
                            dynamic_part = path_parts[segment_index]
                            dynamic_category_path = category_path + (dynamic_part,)
                            scores.setdefault(dynamic_category_path, 0)
                            scores[dynamic_category_path] += weight
                        else: # è·¯å¾„ä¸æ»¡è¶³ï¼Œåˆ™æŒ‰åŸºç¡€è·¯å¾„åŠ åˆ†
                            scores[category_path] += weight
                    else:
                        scores[category_path] += weight

        # --- 2. å†…å®¹æ ¼å¼è§„åˆ™å¤„ç†å™¨ ---
        elif rule_type == "format_rules":
            rules = config.get("format_rules", {})
            for category_path_str, rule in rules.items():
                category_path = tuple(category_path_str.split('/'))
                weight = rule.get("weight", 10) # æ ¼å¼åŒ¹é…æƒé‡æœ€é«˜
                matched = False
                if any(d in domain for d in rule.get("domains", [])):
                    matched = True
                if not matched and any(c in url for c in rule.get("url_contains", [])):
                    matched = True
                if not matched and any(url.lower().endswith(e) for e in rule.get("url_ends_with", [])):
                    matched = True
                
                if matched:
                    scores.setdefault(category_path, 0)
                    scores[category_path] += weight

        # --- 3. "ç¨åé˜…è¯»"è§„åˆ™å¤„ç†å™¨ ---
        elif rule_type == "read_later_rules":
            rule = config.get("read_later_rules", {})
            category_path_str = rule.get("category_name", "ç¨åé˜…è¯»")
            category_path = tuple(category_path_str.split('/'))
            weight = rule.get("weight", 20) # ç¨åé˜…è¯»å…·æœ‰é«˜ä¼˜å…ˆçº§
            matched = False
            # åŸŸååŒ¹é…
            if any(d in domain for d in rule.get("domains", [])):
                # æ£€æŸ¥è·¯å¾„é™åˆ¶
                restrictions = rule.get("path_restrictions", {})
                if domain in restrictions:
                    if any(p in url for p in restrictions[domain]):
                        matched = True
                else: # æ²¡æœ‰è·¯å¾„é™åˆ¶ï¼Œç›´æ¥åŒ¹é…
                    matched = True
            # æ ‡é¢˜å…³é”®è¯åŒ¹é…
            if not matched and any(kw in lower_title for kw in rule.get("keywords_in_title", [])):
                matched = True
            
            if matched:
                scores.setdefault(category_path, 0)
                scores[category_path] += weight

        # --- 4. é€šç”¨åˆ†ç±»è§„åˆ™å¤„ç†å™¨ (åŸºäºæƒé‡è¯„åˆ†) ---
        elif rule_type == "category_rules":
            rules_config = config.get("category_rules", {})
            for category_path_str, category_data in rules_config.items():
                category_path = tuple(category_path_str.split('/'))
                scores.setdefault(category_path, 0)
                
                for rule in category_data.get("rules", []):
                    weight = rule.get("weight", 1)
                    match_target_str = ""
                    
                    match_type = rule.get("match")
                    if match_type == "domain":
                        match_target_str = domain
                    elif match_type == "url":
                        match_target_str = url
                    elif match_type == "title":
                        match_target_str = lower_title
                    
                    if not match_target_str:
                        continue
                        
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä¸€å…³é”®è¯
                    if any(kw in match_target_str for kw in rule.get("keywords", [])):
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä¸€æ’é™¤è¯
                        if any(nkw in match_target_str for nkw in rule.get("must_not_contain", [])):
                            continue # åŒ…å«æ’é™¤è¯ï¼Œæ­¤æ¡è§„åˆ™ä¸è®¡åˆ†
                        
                        scores[category_path] += weight

    # --- å…¨å±€è¯„åˆ†ç»“æŸï¼Œé€‰å‡ºæœ€ä¼˜åˆ†ç±» ---
    if not scores:
        return "æœªåˆ†ç±»", (url, title)

    best_category = max(scores, key=scores.get)
    highest_score = scores[best_category]
    
    # è·å–è¯¥åˆ†ç±»çš„æœ€ä½åˆ†æ•°é˜ˆå€¼
    category_path_str = '/'.join(best_category)
    # åœ¨ category_rules ä¸­å¯»æ‰¾é˜ˆå€¼å®šä¹‰
    min_score = config.get("category_rules", {}).get(category_path_str, {}).get("min_score", 0)

    # å¦‚æœåœ¨ category_rules ä¸­æ²¡æ‰¾åˆ°ï¼Œå¯èƒ½æ˜¯åœ¨å…¶ä»–è§„åˆ™ç±»å‹ä¸­å®šä¹‰çš„
    if min_score == 0:
        for rule_type in ["special_domain_rules", "format_rules", "read_later_rules"]:
            rules = config.get(rule_type, {})
            # æ³¨æ„: "read_later_rules" ç»“æ„ä¸åŒï¼Œéœ€è¦å•ç‹¬å¤„ç†
            if rule_type == "read_later_rules":
                 if rules.get("category_name", "ç¨åé˜…è¯»") == category_path_str:
                    min_score = rules.get("min_score", 0)
                    break
            elif category_path_str in rules:
                min_score = rules.get(category_path_str, {}).get("min_score", 0)
                break

    if highest_score > min_score:
        return best_category, (url, title)

    return "æœªåˆ†ç±»", (url, title)


def build_structure(categorized_bookmarks):
    """æ ¹æ® categorized_bookmarks æ„é€ å¤šå±‚åµŒå¥— dictï¼Œä¾›åç»­ HTML / Markdown å¤ç”¨"""
    structured = {}

    def add_nested(path_tuple, item):
        cur = structured
        for idx, key in enumerate(path_tuple):
            is_last = idx == len(path_tuple) - 1
            if key not in cur:
                cur[key] = {"_items": []} if is_last else {}
            cur = cur[key]
        if "_items" not in cur:
            cur["_items"] = []
        cur["_items"].append(item)

    for path, (url, title) in categorized_bookmarks:
        if isinstance(path, tuple):
            add_nested(path, (url, title))
        else:
            add_nested((path,), (url, title))
    
    def simplify_single_item_folders(node):
        """
        é€’å½’åœ°åˆå¹¶åªåŒ…å«å•ä¸ªä¹¦ç­¾ä¸”æ— å­æ–‡ä»¶å¤¹çš„ç›®å½•ã€‚
        è¿™ä¸ªå®ç°é€šè¿‡æ„å»ºæ–°å­—å…¸æ¥é¿å…è¿­ä»£æ—¶ä¿®æ”¹çš„å‰¯ä½œç”¨ã€‚
        """
        if not isinstance(node, dict):
            return node

        # 1. é¦–å…ˆï¼Œé€’å½’ç®€åŒ–æ‰€æœ‰å­èŠ‚ç‚¹
        simplified_children = {}
        for key, value in node.items():
            if key != "_items":
                simplified_children[key] = simplify_single_item_folders(value)

        # 2. ç„¶åï¼ŒåŸºäºç®€åŒ–åçš„å­èŠ‚ç‚¹ï¼Œæ„å»ºå½“å‰å±‚çº§çš„æ–°èŠ‚ç‚¹
        new_node = {}
        # å…ˆæŠŠå½“å‰å±‚çº§çš„ä¹¦ç­¾å¸¦è¿‡æ¥
        if "_items" in node:
            new_node["_items"] = node["_items"]

        for key, simplified_child in simplified_children.items():
            # æ£€æŸ¥è¿™ä¸ªç®€åŒ–åçš„å­èŠ‚ç‚¹æ˜¯å¦å¯ä»¥è¢«åˆå¹¶
            has_subfolders = any(k != "_items" for k in simplified_child)
            is_single_bookmark = len(simplified_child.get("_items", [])) == 1

            if not has_subfolders and is_single_bookmark:
                # æ˜¯å•é¡¹æ–‡ä»¶å¤¹ï¼Œå°†å…¶ä¸­çš„ä¹¦ç­¾"æèµ·"åˆ°å½“å‰å±‚çº§
                single_item = simplified_child["_items"][0]
                if "_items" not in new_node:
                    new_node["_items"] = []
                
                new_title = f"[{key}] {single_item[1]}"
                new_node["_items"].append((single_item[0], new_title))
            else:
                # ä¸æ˜¯å•é¡¹æ–‡ä»¶å¤¹ï¼Œä¿æŒåŸæ ·
                new_node[key] = simplified_child
        
        return new_node

    # ä¸è¦å¯¹é¡¶å±‚ç»“æ„æœ¬èº«è¿›è¡Œç®€åŒ–ï¼Œè€Œæ˜¯å¯¹æ¯ä¸ªé¡¶å±‚åˆ†ç±»çš„å†…éƒ¨è¿›è¡Œç®€åŒ–
    # return simplify_single_item_folders(structured) # æ—§çš„ã€é”™è¯¯çš„æ–¹å¼

    simplified_structure = {}
    for top_level_cat, content in structured.items():
        simplified_structure[top_level_cat] = simplify_single_item_folders(content)

    return simplified_structure


def generate_markdown(structured_bookmarks, md_file):
    """é€’å½’ç”Ÿæˆå…·æœ‰æ ‡å‡†å¤šçº§æ ‡é¢˜å’Œæ’åºçš„ Markdown æ–‡ä»¶"""
    lines = []

    def walk(node, depth=0):
        # å¯¹å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰é”®ï¼ˆå­ç›®å½•å’Œ _itemsï¼‰è¿›è¡Œæ’åºï¼Œç¡®ä¿è¾“å‡ºé¡ºåºç¨³å®š
        # å°† _items å•ç‹¬å¤„ç†ï¼Œå…¶ä»–é”®ï¼ˆå­ç›®å½•ï¼‰æŒ‰å­—æ¯é¡ºåºæ’åº
        sorted_keys = sorted([k for k in node.keys() if k != "_items"])

        # 1. é¦–å…ˆå¤„ç†å½“å‰å±‚çº§çš„æ‰€æœ‰å­ç›®å½•
        for key in sorted_keys:
            value = node[key]
            # åŠ¨æ€ç”Ÿæˆæ ‡é¢˜çº§åˆ«, ä¾‹å¦‚ #, ##, ###
            # ä¸ºäº†ç¾è§‚å’Œå…¼å®¹æ€§ï¼Œé™åˆ¶æœ€å¤§æ ‡é¢˜çº§åˆ«åˆ° H4 (####)
            heading_level = min(depth + 1, 4)
            heading_prefix = "#" * heading_level
            lines.append(f"\n{heading_prefix} {key}\n")
            walk(value, depth + 1)

        # 2. ç„¶åå¤„ç†å½“å‰å±‚çº§çš„æ‰€æœ‰ä¹¦ç­¾é¡¹
        if "_items" in node:
            # å¯¹å½“å‰å±‚çº§çš„ä¹¦ç­¾æŒ‰æ ‡é¢˜è¿›è¡Œæ’åº
            sorted_items = sorted(node["_items"], key=lambda item: item[1])
            for url, title in sorted_items:
                # ä¹¦ç­¾ä½¿ç”¨æ— åºåˆ—è¡¨æ ¼å¼
                lines.append(f"- [{title}]({url})")

    # ä»é¡¶å±‚å¼€å§‹éå†ï¼Œåˆå§‹æ·±åº¦ä¸º0
    walk(structured_bookmarks, depth=0)
    with open(md_file, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))


def create_bookmark_html(structured_bookmarks, output_file):
    """
    æ ¹æ®æ„é€ å¥½çš„ä¹¦ç­¾ç»“æ„ï¼Œç”Ÿæˆ Netscape-Bookmark-file-1 æ ¼å¼çš„ HTML æ–‡ä»¶ã€‚

    è¿™ç§æ ¼å¼çš„æ–‡ä»¶å¯ä»¥è¢«ä¸»æµæµè§ˆå™¨ï¼ˆå¦‚ Chrome, Edge, Firefoxï¼‰æ­£ç¡®è¯†åˆ«å’Œå¯¼å…¥ã€‚

    Args:
        structured_bookmarks (dict): ç»è¿‡ `build_structure` å‡½æ•°å¤„ç†åçš„åµŒå¥—å­—å…¸ã€‚
        output_file (str): è¾“å‡º HTML æ–‡ä»¶çš„è·¯å¾„ã€‚
    """
    ts = str(int(time.time()))
    lines = [
        "<!DOCTYPE NETSCAPE-Bookmark-file-1>",
        "<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=UTF-8\">",
        "<TITLE>Bookmarks</TITLE>",
        "<H1>Bookmarks</H1>",
        "<DL><p>"
    ]

    def write_folder(name, content_dict, indent=1):
        ind = "    " * indent
        lines.append(f"{ind}<DT><H3 ADD_DATE=\"{ts}\" LAST_MODIFIED=\"{ts}\">{name}</H3>")
        lines.append(f"{ind}<DL><p>")
        # éå†å­å…ƒç´ 
        for key, value in sorted(content_dict.items()):
            if key == "_items":
                for url, title in value:
                    lines.append(f"{ind}    <DT><A HREF=\"{url}\" ADD_DATE=\"{ts}\">{title}</A>")
            else:
                write_folder(key, value, indent + 1)
        lines.append(f"{ind}</DL><p>")

    # æŒ‰å›ºå®šé¡ºåºå†™é¡¶å±‚ï¼Œä»¥ä¿æŒä¸€è‡´
    top_order = [
        "å·¥ä½œå°", "ç”Ÿç‰©ä¿¡æ¯", "AI ç ”ç©¶å®¤", "æŠ€æœ¯æ ˆ", "æ•ˆç‡å·¥å…·", "å­¦ä¹  & é˜…è¯»", "ä¼‘é—²å¨±ä¹", "ç¨åé˜…è¯»", "æœªåˆ†ç±»"
    ]
    for cat in top_order:
        if cat in structured_bookmarks:
            write_folder(cat, structured_bookmarks[cat])
    # é’ˆå¯¹å¯èƒ½æ–°å¢çš„å…¶ä»–é¡¶å±‚ç±»åˆ«
    for cat in sorted(structured_bookmarks.keys()):
        if cat not in top_order:
            write_folder(cat, structured_bookmarks[cat])

    lines.append("</DL><p>")

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))


def _count_bookmarks_recursive(node):
    """é€’å½’åœ°ç»Ÿè®¡ä¸€ä¸ªèŠ‚ç‚¹ä¸‹ä¹¦ç­¾çš„æ€»æ•°"""
    if not isinstance(node, dict):
        return 0
    count = len(node.get("_items", []))
    for key, value in node.items():
        if key != "_items":
            count += _count_bookmarks_recursive(value)
    return count

def print_statistics(structured_data, total_links_found, unique_links_count):
    """
    æ‰“å°å…³äºä¹¦ç­¾é›†åˆçš„ã€æœ‰è¶£çš„ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    print("\nğŸ“Š----- ä¹¦ç­¾ç»Ÿè®¡ä¿¡æ¯ -----ğŸ“Š")
    
    # 1. å»é‡ç»Ÿè®¡
    duplicates_found = total_links_found - unique_links_count
    print(f"âœ¨ å»é‡æˆæœ: å…±æ‰¾åˆ°å¹¶ç§»é™¤äº† {duplicates_found} ä¸ªé‡å¤é“¾æ¥ã€‚")

    # 2. å„åˆ†ç±»ä¹¦ç­¾æ•°é‡
    print("\nğŸ“š å„åˆ†ç±»ä¹¦ç­¾æ•°é‡:")
    category_counts = {}
    all_domains = []
    for category, content in structured_data.items():
        category_counts[category] = _count_bookmarks_recursive(content)
        
        # é¡ºä¾¿æ”¶é›†åŸŸåç”¨äºåç»­ç»Ÿè®¡
        def collect_domains(node):
            if not isinstance(node, dict): return
            for url, title in node.get("_items", []):
                try:
                    all_domains.append(_parse_url_cached(url).netloc.lower())
                except:
                    pass # å¿½ç•¥æ— æ³•è§£æçš„URL
            for key, value in node.items():
                if key != "_items":
                    collect_domains(value)
        collect_domains(content)
    
    # æ’åºå¹¶æ‰“å°åˆ†ç±»ç»Ÿè®¡
    if category_counts:
        sorted_categories = sorted(category_counts.items(), key=lambda item: item[1], reverse=True)
        for category, count in sorted_categories:
            print(f"  - {category:<20} : {count} ä¸ª") # å·¦å¯¹é½ï¼Œæ–¹ä¾¿é˜…è¯»

    # 3. Top 5 åŸŸå
    if all_domains:
        print("\nğŸŒ æ‚¨æœ€å¸¸è®¿é—®çš„ Top 5 ç½‘ç«™:")
        top_5_domains = Counter(all_domains).most_common(5)
        for i, (domain, count) in enumerate(top_5_domains):
            print(f"  {i+1}. {domain} ({count} æ¬¡)")
        
    print("--------------------------\n")


def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œä¹¦ç­¾æ¸…ç†å’Œåˆ†ç±»çš„æ ¸å¿ƒæµç¨‹ã€‚
    æ”¯æŒå¤šç­–ç•¥é…ç½®é€‰æ‹©ã€‚
    """
    parser = argparse.ArgumentParser(
        description="æ¸…ç†ã€åˆå¹¶å¹¶åˆ†ç±»æµè§ˆå™¨å¯¼å‡ºçš„ HTML ä¹¦ç­¾æ–‡ä»¶ã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        '-i', '--input',
        nargs='+',
        default=[],
        help='ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥çš„ HTML ä¹¦ç­¾æ–‡ä»¶è·¯å¾„ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰ã€‚\nå¦‚æœæœªæä¾›ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨æ‰«æ "tests/input" ç›®å½•ã€‚'
    )
    parser.add_argument(
        '-c', '--config',
        default=None, # é»˜è®¤å€¼æ”¹ä¸º Noneï¼Œä»¥ä¾¿æ£€æµ‹ç”¨æˆ·æ˜¯å¦æŒ‡å®š
        help='æŒ‡å®šåˆ†ç±»è§„åˆ™çš„ JSON é…ç½®æ–‡ä»¶è·¯å¾„ã€‚\nå¦‚æœæœªæä¾›ï¼Œå°†è‡ªåŠ¨æœç´¢ config_*.json æ–‡ä»¶å¹¶æä¾›é€‰æ‹©ã€‚'
    )
    parser.add_argument(
        '--output-html',
        default='tests/output/bookmarks_cleaned.html',
        help='è¾“å‡ºçš„å·²æ¸…ç† HTML æ–‡ä»¶è·¯å¾„ã€‚\né»˜è®¤å€¼: tests/output/bookmarks_cleaned.html'
    )
    parser.add_argument(
        '--output-md',
        default='tests/output/bookmarks.md',
        help='è¾“å‡ºçš„ Markdown æ–‡ä»¶è·¯å¾„ã€‚\né»˜è®¤å€¼: tests/output/bookmarks.md'
    )
    args = parser.parse_args()

    config_file = args.config
    
    # --- å¤šç­–ç•¥é…ç½®é€‰æ‹© ---
    if not config_file:
        # ä¼˜å…ˆå¯»æ‰¾ä¸»é…ç½®æ–‡ä»¶
        available_configs = []
        if os.path.exists('config.json'):
            available_configs.append('config.json')
        
        # å¯»æ‰¾å…¶ä»–ç­–ç•¥æ–‡ä»¶
        other_configs = sorted(glob.glob('config_*.json'))
        for cfg in other_configs:
            if cfg not in available_configs:
                available_configs.append(cfg)

        if not available_configs:
            print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•é…ç½®æ–‡ä»¶ï¼ˆconfig.json æˆ– config_*.jsonï¼‰ã€‚")
            return
        elif len(available_configs) == 1:
            config_file = available_configs[0]
            print(f"âœ… æ£€æµ‹åˆ°å•ä¸ªé…ç½®ï¼Œå·²è‡ªåŠ¨é€‰æ‹©: {config_file}")
        else:
            print("\nè¯·é€‰æ‹©è¦ä½¿ç”¨çš„åˆ†ç±»ç­–ç•¥ï¼š")
            # å°† config.json æ ‡è®°ä¸ºé»˜è®¤
            for i, f in enumerate(available_configs):
                default_marker = " (é»˜è®¤æœ€å¼ºç­–ç•¥)" if f == 'config.json' else ""
                print(f"  [{i + 1}] {f}{default_marker}")
            
            while True:
                try:
                    choice_str = input("è¯·è¾“å…¥é€‰é¡¹ç¼–å· (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ")
                    if not choice_str and 'config.json' in available_configs:
                        config_file = 'config.json'
                        break
                    
                    choice = int(choice_str)
                    if 1 <= choice <= len(available_configs):
                        config_file = available_configs[choice - 1]
                        break
                    else:
                        print("âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥åˆ—è¡¨ä¸­çš„ç¼–å·ã€‚")
                except ValueError:
                    print("âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ•°å­—ã€‚")
            print(f"âœ… æ‚¨å·²é€‰æ‹©ç­–ç•¥: {config_file}")


    input_files = args.input
    # å¦‚æœæ²¡æœ‰é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æä¾›è¾“å…¥æ–‡ä»¶ï¼Œåˆ™ä»é»˜è®¤ç›®å½•æ‰«æ
    if not input_files:
        input_dir = 'tests/input'
        if os.path.isdir(input_dir):
            print(f"âœ… ä¿¡æ¯ï¼šæœªä»å‘½ä»¤è¡Œè·å–è¾“å…¥ï¼Œå°†è‡ªåŠ¨æ‰«æ '{input_dir}' ç›®å½•ã€‚")
            input_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.html')]
        else:
            print(f"âŒ é”™è¯¯ï¼šé»˜è®¤è¾“å…¥ç›®å½• '{input_dir}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªç›®å½•ã€‚è¯·ä½¿ç”¨ --input å‚æ•°æŒ‡å®šæ–‡ä»¶ã€‚")
            return
            
    if not input_files:
        print(f"âŒ é”™è¯¯ï¼šåœ¨æŒ‡å®šçš„è·¯å¾„æˆ–é»˜è®¤ç›®å½• 'tests/input' ä¸­æœªæ‰¾åˆ°ä»»ä½• .html ä¹¦ç­¾æ–‡ä»¶ã€‚")
        return

    output_html_file = args.output_html
    output_md_file = args.output_md

    # --- ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ ---
    output_dir = os.path.dirname(output_html_file)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")

    # --- åŠ è½½é…ç½® ---
    if not os.path.exists(config_file):
        print(f"âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ '{config_file}' ä¸å­˜åœ¨ã€‚")
        return
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
    except json.JSONDecodeError:
        print(f"âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ '{config_file}' æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ JSONã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šåŠ è½½é…ç½®æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return
    # --- é…ç½®åŠ è½½å®Œæ¯• ---

    all_links = []
    print(f"\nğŸ“– å¼€å§‹å¤„ç† {len(input_files)} ä¸ªä¹¦ç­¾æ–‡ä»¶...")

    for input_file in input_files:
        if not os.path.exists(input_file):
            print(f"âš ï¸ è­¦å‘Šï¼šè¾“å…¥æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
            continue
        
        print(f"   - æ­£åœ¨è¯»å–: {input_file}")
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        soup = BeautifulSoup(content, 'lxml')
        links = soup.find_all('a')
        all_links.extend(links)

    if not all_links:
        print("âŒ é”™è¯¯ï¼šæœªèƒ½åœ¨ä»»ä½•è¾“å…¥æ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„ä¹¦ç­¾é“¾æ¥ã€‚")
        return

    print(f"\nğŸ” å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¹¦ç­¾é“¾æ¥ï¼ˆåˆå¹¶åï¼‰ã€‚")

    unclassified_log = []
    categorized_bookmarks = []
    seen_urls = set()

    print("ğŸš€ å¼€å§‹åˆ†ç±»å’Œå»é‡...")
    for link in all_links:
        url = link.get('href')
        title = link.string
        if url and title:
            category, item = classify_bookmark(url, title.strip(), seen_urls, config)
            if category and item:
                # item æ˜¯ä¸€ä¸ªå…ƒç»„ (cleaned_url, original_title)
                cleaned_url, original_title = item
                cleaned_title = clean_title(original_title, config)
                categorized_bookmarks.append((category, (cleaned_url, cleaned_title)))
                if category == "æœªåˆ†ç±»":
                    # æ—¥å¿—ä¸­è®°å½•åŸå§‹çš„ URL å’Œæ ‡é¢˜ï¼Œä¾¿äºè°ƒè¯•
                    unclassified_log.append(f"{url} | {title.strip()}")

    if unclassified_log:
        log_file_path = "unclassified_log.txt"
        print(f"æ­£åœ¨å°† {len(unclassified_log)} ä¸ªæœªåˆ†ç±»ä¹¦ç­¾å†™å…¥æ—¥å¿—: {log_file_path}")
        with open(log_file_path, "w", encoding="utf-8") as f:
            f.write("\n".join(unclassified_log))

    print(f"âœ… åˆ†ç±»å®Œæˆï¼å…±æ•´ç†å‡º {len(categorized_bookmarks)} ä¸ªæœ‰æ•ˆä¹¦ç­¾ã€‚")
    
    structured_data = build_structure(categorized_bookmarks)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print_statistics(structured_data, len(all_links), len(seen_urls))
    
    print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆ Markdown è¾“å‡º: {output_md_file}")
    generate_markdown(structured_data, output_md_file)
    
    print(f"ğŸŒ æ­£åœ¨ç”Ÿæˆ HTML è¾“å‡º: {output_html_file}")
    create_bookmark_html(structured_data, output_html_file)
    
    print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")


if __name__ == '__main__':
    main()