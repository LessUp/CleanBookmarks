# AI 助力的浏览器书签智能分类系统 - 设计文档

## 1. 项目背景与目标

### 1.1. 当前系统的现状与挑战

当前的书签整理脚本 (`clean_marks.py`) 采用一套基于 `config.json` 的规则引擎。该引擎通过关键词匹配、域名判断和加权评分等方式对书签进行分类。

**优点：**
- **确定性强**：规则明确，分类结果可预测、可解释。
- **配置灵活**：用户可以通过修改 JSON 文件来自定义分类逻辑，无需改动代码。

**挑战：**
- **规则维护成本高**：随着书签增多，需要不断地调整关键词、权重和排除项，过程繁琐且难以达到最优。
- **泛化能力弱**：无法处理未在规则中定义的、语义相近但用词不同的新内容。例如，规则里有 `教程`，但无法自动识别 `指南`、`cheatsheet` 或 `step-by-step`。
- **处理模糊性能力差**：对于可以归入多个分类的书签，规则系统通常只能"一刀切"地归于一个，可能不是最理想的选择。

### 1.2. 目标：引入 AI，实现智能分类

为了克服上述挑战，我们计划引入机器学习（AI）模型，将书签分类从"手动规则驱动"升级为"数据驱动"。

**核心目标：**
- **提升分类准确率**：利用 AI 模型的学习能力，更精准地理解书签内容，做出比复杂规则更优的分类判断。
- **降低维护成本**：将主要维护工作从"编写复杂规则"转变为"标注高质量数据"，一次投入，长期受益。
- **增强系统适应性**：模型能够从新数据中持续学习，自动适应不断变化的书签内容。
- **保留规则系统的优点**：采用**"规则 + AI"**的混合策略，保留部分确定性高的规则，将复杂和模糊的分类任务交给 AI，实现两者的优势互补。

---

## 2. 整体方案架构

我们将整个方案设计为三个核心阶段，确保流程清晰、易于实施和维护。

```mermaid
graph TD
    subgraph "阶段一：数据准备"
        A[1. 运行现有脚本] --> B{bookmarks.md};
        B --> C[2. 人工校对与修正];
        C --> D[3. 生成 labeled_bookmarks.csv];
    end

    subgraph "阶段二：模型训练"
        direction LR
        D --> E[train_model.py];
        E --> F[4. 特征提取<br/>(TfidfVectorizer)];
        F --> G[5. 训练分类器<br/>(Naive Bayes/Logistic Regression)];
        G --> H[bookmark_classifier.joblib];
    end

    subgraph "阶段三：集成与应用"
        I[clean_marks.py] --> J{6. 加载模型<br/>bookmark_classifier.joblib};
        J --> K[7. 改造分类函数];
        subgraph "混合分类策略"
            direction TB
            L[输入书签] --> M{高优先级规则<br>如 "稍后阅读"};
            M -- 命中 --> N[直接分类];
            M -- 未命中 --> O{调用 AI 模型预测};
            O --> P[智能分类];
        end
        K --> P;
    end

    style D fill:#f9f,stroke:#333,stroke-width:2px
    style H fill:#f9f,stroke:#333,stroke-width:2px
```

### 工作流程概述：
1.  **数据准备**：利用现有脚本的初步成果，通过人工校对，创建一份高质量的、带"标准答案"的标注数据集 (`labeled_bookmarks.csv`)。
2.  **模型训练**：创建一个独立的训练脚本 (`train_model.py`)，该脚本读取标注数据，使用 `scikit-learn` 库来训练一个文本分类模型，并将其保存为文件 (`bookmark_classifier.joblib`)。
3.  **集成与应用**：修改主脚本 (`clean_marks.py`)，使其能够加载并使用训练好的模型。我们将实现一个混合分类逻辑：优先应用一些简单的、确定性高的规则，对于其他书签，则调用 AI 模型来预测其最佳分类。

---

## 3. 分阶段实施计划

### 3.1. 阶段一：数据准备与标注 (`labeled_bookmarks.csv`)

这是整个项目成功的基石。模型的质量直接取决于训练数据的质量。

1.  **数据格式**：
    我们将创建一个 `CSV` 文件 `labeled_bookmarks.csv`，包含三列：
    - `url`: 书签的原始 URL。
    - `title`: 书签的标题。
    - `category`: **人工校对后**的正确分类路径，例如 `技术栈/Python` 或 `AI 研究室`。

2.  **数据获取与标注流程（冷启动）**：
    a. **初步运行**：不带任何参数运行 `python src/clean_marks.py`，让现有规则系统处理 `tests/input` 目录下的所有书签。
    b. **获取初步结果**：脚本会生成 `tests/output/bookmarks.md` 和 `unclassified_log.txt`。
    c. **人工校对**：
        - 检查 `bookmarks.md` 中各个分类下的书签，找出**分错了**的。
        - 检查 `unclassified_log.txt` 中所有**未被分类**的书签。
    d. **创建标注数据**：将上述找到的分错或未分类的书签，连同您认为的**正确分类**，一起填入 `labeled_bookmarks.csv` 文件中。
    e. **数据量**：初期目标是为每个主要分类提供 **20-50条** 标注样本，总数据量达到 **200-500条** 即可开始训练一个有效的基础模型。

### 3.2. 阶段二：模型训练 (`train_model.py`)

我们将创建一个新的 Python 脚本 `src/train_model.py` 来专门负责模型训练。

1.  **依赖库**：
    - `pandas`: 用于读取和处理 `CSV` 数据。
    - `scikit-learn`: 用于特征提取、模型训练和评估。
    - `joblib`: 用于保存和加载训练好的模型。
    
    *这些依赖需要被添加到 `requirements.txt` 文件中。*

2.  **脚本核心逻辑**：
    a. **加载数据**：使用 `pandas.read_csv` 读取 `labeled_bookmarks.csv`。
    b. **特征工程 (Feature Engineering)**：
        - 将 `title` 和 `url` 的关键部分（如域名、路径）合并成一个文本字段，作为模型的输入特征。
        - 使用 `TfidfVectorizer` 将该文本字段转换为数值向量。`TF-IDF` 是一种强大的文本表示方法，能自动评估单词对于分类的重要性。
    c. **数据拆分**：将标注数据按 80/20 的比例拆分为**训练集**和**测试集**。
    d. **模型选择与训练**：
        - 选用**朴素贝叶斯 (`MultinomialNB`)** 或 **逻辑回归 (`LogisticRegression`)** 作为分类器。这两种模型都是经典的文本分类算法，训练速度快，效果好，且对算力要求低。
        - 在训练集上调用 `.fit()` 方法进行训练。
    e. **模型评估**：在测试集上进行预测，并计算准确率（Accuracy）、精确率（Precision）、召回率（Recall）等指标，以评估模型性能。
    f. **模型序列化**：将训练好的 `TfidfVectorizer` 和分类器打包，使用 `joblib.dump` 保存为一个单独的文件 `bookmark_classifier.joblib`。

### 3.3. 阶段三：集成到 `clean_marks.py`

最后一步是将我们训练的 AI 模型应用到主流程中。

1.  **加载模型**：在 `clean_marks.py` 的 `main` 函数开始处，检查 `bookmark_classifier.joblib` 文件是否存在，如果存在则使用 `joblib.load` 加载。

2.  **创建新的分类函数**：
    - 新增一个函数 `classify_with_ai(url, title, model)`。
    - 该函数接收 URL 和标题，并使用加载的模型（包含 `Vectorizer` 和分类器）对其进行处理和预测，最终返回一个分类字符串。

3.  **改造 `classify_bookmark` 函数**：
    - 将其改造为混合模式。
    - **优先规则**：首先执行一些简单、高优先级的规则。例如，"稍后阅读"规则可以通过简单的关键词和域名匹配实现，这类规则确定性高，可以保留。
    - **AI 分类**：如果书签没有被任何优先规则命中，则**不再执行后续复杂的加权评分逻辑**，而是直接调用 `classify_with_ai` 函数，将分类任务交给模型来完成。
    - **未分类处理**：如果模型也无法给出一个置信度高的分类（可选功能），或模型不存在，则依然可以将其归为"未分类"。

---

## 4. 技术选型与理由

- **核心框架**：`scikit-learn`
  - **理由**：业界领先的 Python 机器学习库，社区成熟，文档丰富。它提供了本项目所需的全部工具链（数据处理、特征提取、模型训练、评估），且性能高效稳定。
- **特征提取**：`TfidfVectorizer`
  - **理由**：文本分类任务的基准方法，能有效捕捉关键词信息，并自动处理停用词（如 "a", "the", "的"），非常适合本项目场景。
- **分类算法**：`MultinomialNB` (朴素贝叶斯) 或 `LogisticRegression` (逻辑回归)
  - **理由**：对于文本分类问题，这两种算法通常是首选的基线模型。它们训练速度快，对硬件要求低（完全可以在普通笔记本上秒级完成训练），且往往能达到非常不错的分类效果。

---

## 5. 未来展望

本方案为书签分类系统提供了一个可扩展的 AI 框架。未来可以从以下方向进行迭代和优化：

- **主动学习 (Active Learning)**：对于模型预测不确定的书签，脚本可以主动提示用户进行标注，从而最高效地扩充和优化训练数据集。
- **模型定期重训练**：可以建立一个机制，当积累了足够多的新标注数据后，自动触发模型重训练，实现系统的自我进化。
- **尝试更复杂的模型**：如果未来精度要求进一步提高，可以尝试使用 `LightGBM`、`Word2Vec` 或更轻量级的深度学习模型（如 `fastText`）来进一步提升效果。 